{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Final Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nom Etudiant :**  \n",
    "\n",
    "**Prenom Etudiant:**  \n",
    "\n",
    "**Classe :**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Ce projet consiste à utiliser Apache Spark pour faire l'analyse et le traitement des données de **[San Francisco Fire Department Calls ](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)** afin de fournir quelques KPI (*Key Performance Indicator*). Le **SF Fire Dataset** comprend les réponses aux appels de toutes les unités d'incendie. Chaque enregistrement comprend le numéro d'appel, le numéro d'incident, l'adresse, l'identifiant de l'unité, le type d'appel et la disposition. Tous les intervalles de temps pertinents sont également inclus. Étant donné que ce Dataset est basé sur les réponses et que la plupart des appels impliquent plusieurs unités, ainsi il existe plusieurs enregistrements pour chaque numéro d'appel. Les adresses sont associées à un numéro de bloc, à une intersection ou à une boîte d'appel, et non à une adresse spécifique.\n",
    "\n",
    "**Plus de details sur la description des données cliquer sur ce [lien](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail à faire.\n",
    "L'objectif de ce projet est de comprendre le **SF Fire Dataset** afin de bien répondre aux questions en utilisant les codes Spark/Scala adéquates.\n",
    "\n",
    "- Créer un repos git (public) et partager le repos avec mon mail (limahin10@gmail.com)\n",
    "- Ecrire un code lisible et bien indenté \n",
    "- N'oublier pas de mettre en commentaire la justification de vos réponses sur les cellules Markdown. \n",
    "\n",
    "\n",
    "## Note:\n",
    "- Le projet est personnel, c'est-à-dire chaque notebook ne concerne qu'un seul étudiant. \n",
    "- Deadline : **Lundi 31 Janvier 2022  à 23h 59** (Aucune de dérogation ne sera acceptée)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des packages Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.sql.functions._\n",
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._ \n",
    "import org.apache.spark.sql.functions._ \n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons jeter un coup d'oeil sur la structure des données avant de définir un schéma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CallNumber,UnitID,IncidentNumber,CallType,CallDate,WatchDate,CallFinalDisposition,AvailableDtTm,Address,City,Zipcode,Battalion,StationArea,Box,OriginalPriority,Priority,FinalPriority,ALSUnit,CallTypeGroup,NumAlarms,UnitType,UnitSequenceInCallDispatch,FirePreventionDistrict,SupervisorDistrict,Neighborhood,Location,RowID,Delay\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!head -1 \"datasets/sf-fire/sf-fire-calls.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vu que la taille de ces données est énormes, inferer le schema pour un très grande volumes de données s'avère un peu couteux. Nous allons ainsi définir un schema pour le Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fireSchema: org.apache.spark.sql.types.StructType = StructType(StructField(CallNumber,IntegerType,true), StructField(UnitID,StringType,true), StructField(IncidentNumber,IntegerType,true), StructField(CallType,StringType,true), StructField(CallDate,StringType,true), StructField(WatchDate,StringType,true), StructField(CallFinalDisposition,StringType,true), StructField(AvailableDtTm,StringType,true), StructField(Address,StringType,true), StructField(City,StringType,true), StructField(Zipcode,IntegerType,true), StructField(Battalion,StringType,true), StructField(StationArea,StringType,true), StructField(Box,StringType,true), StructField(OriginalPriority,StringType,true), StructField(Priority,StringType,true), StructField(FinalPriority,IntegerType,true), StructField(ALSUnit,BooleanType,true)...\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fireSchema = StructType(Array(StructField(\"CallNumber\", IntegerType, true),\n",
    "  StructField(\"UnitID\", StringType, true),\n",
    "  StructField(\"IncidentNumber\", IntegerType, true),\n",
    "  StructField(\"CallType\", StringType, true),                  \n",
    "  StructField(\"CallDate\", StringType, true),      \n",
    "  StructField(\"WatchDate\", StringType, true),\n",
    "  StructField(\"CallFinalDisposition\", StringType, true),\n",
    "  StructField(\"AvailableDtTm\", StringType, true),\n",
    "  StructField(\"Address\", StringType, true),       \n",
    "  StructField(\"City\", StringType, true),       \n",
    "  StructField(\"Zipcode\", IntegerType, true),       \n",
    "  StructField(\"Battalion\", StringType, true),                 \n",
    "  StructField(\"StationArea\", StringType, true),       \n",
    "  StructField(\"Box\", StringType, true),       \n",
    "  StructField(\"OriginalPriority\", StringType, true),       \n",
    "  StructField(\"Priority\", StringType, true),       \n",
    "  StructField(\"FinalPriority\", IntegerType, true),       \n",
    "  StructField(\"ALSUnit\", BooleanType, true),       \n",
    "  StructField(\"CallTypeGroup\", StringType, true),\n",
    "  StructField(\"NumAlarms\", IntegerType, true),\n",
    "  StructField(\"UnitType\", StringType, true),\n",
    "  StructField(\"UnitSequenceInCallDispatch\", IntegerType, true),\n",
    "  StructField(\"FirePreventionDistrict\", StringType, true),\n",
    "  StructField(\"SupervisorDistrict\", StringType, true),\n",
    "  StructField(\"Neighborhood\", StringType, true),\n",
    "  StructField(\"Location\", StringType, true),\n",
    "  StructField(\"RowID\", StringType, true),\n",
    "  StructField(\"Delay\", FloatType, true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sfFireFile: String = datasets/sf-fire/sf-fire-calls.csv\n",
       "fireDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sfFireFile = \"datasets/sf-fire/sf-fire-calls.csv\"\n",
    "val fireDF = spark\n",
    "  .read\n",
    "  .schema(fireSchema)\n",
    "  .option(\"header\", \"true\")\n",
    "  .csv(sfFireFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons mettre en cache le Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: fireDF.type = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fireDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Long = 175296\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fireDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         null|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         null|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         null|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         null|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         null|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrage des d'appels de type \"Medical Incident\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fewFireDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [IncidentNumber: int, AvailableDtTm: string ... 1 more field]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fewFireDF = fireDF\n",
    "  .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\") \n",
    "  .where($\"CallType\" =!= \"Medical Incident\")\n",
    "fewFireDF.show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "**Combien de types d'appels distincts ont été passés ?**  \n",
    "Pour être sûr, il ne faut pas compter les valeurs «nulles» dans la colonne.\n",
    "### Reponse 1\n",
    "j'ai utilisé filter() pour filtrer les valeurs non nulles et distinct() pour eliminer les doublons.\n",
    "Le nombre de types d'appels distincts qui ont été passés est 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: Long = 30\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fireDF\n",
    ".select(\"CallType\")\n",
    ".filter(col(\"CallType\").isNotNull)\n",
    ".distinct()\n",
    ".count()\n",
    "\n",
    "/*val distinctsCallType = data.agg(countDistinct(\"CallType\"))\n",
    "distinctsCallType.show()*/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quels types d'appels différents ont été passés au service d'incendie?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|CallType                                    |\n",
      "+--------------------------------------------+\n",
      "|Elevator / Escalator Rescue                 |\n",
      "|Marine Fire                                 |\n",
      "|Aircraft Emergency                          |\n",
      "|Confined Space / Structure Collapse         |\n",
      "|Administrative                              |\n",
      "|Alarms                                      |\n",
      "|Odor (Strange / Unknown)                    |\n",
      "|Citizen Assist / Service Call               |\n",
      "|HazMat                                      |\n",
      "|Watercraft in Distress                      |\n",
      "|Explosion                                   |\n",
      "|Oil Spill                                   |\n",
      "|Vehicle Fire                                |\n",
      "|Suspicious Package                          |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|\n",
      "|Other                                       |\n",
      "|Outside Fire                                |\n",
      "|Traffic Collision                           |\n",
      "|Assist Police                               |\n",
      "|Gas Leak (Natural and LP Gases)             |\n",
      "|Water Rescue                                |\n",
      "|Electrical Hazard                           |\n",
      "|High Angle Rescue                           |\n",
      "|Structure Fire                              |\n",
      "|Industrial Accidents                        |\n",
      "|Medical Incident                            |\n",
      "|Mutual Aid / Assist Outside Agency          |\n",
      "|Fuel Spill                                  |\n",
      "|Smoke Investigation (Outside)               |\n",
      "|Train / Rail Incident                       |\n",
      "+--------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Reponse 2\n",
    "fireDF.select(\"CallType\").distinct().show(30, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " la methode \"select(\"CallType\").distinct()\" permet d'afficher (Les types distincts de la colonne \"CallType\")\n",
    "\n",
    "j'ai specifié 30 dans la methode .show(30, false) pour pouvoir  afficher les 30 \"CallType\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "**Trouver toutes les réponses ou les délais sont supérieurs à 5 minutes?**\n",
    "\n",
    "*Indication\n",
    "1. Renommer la colonne Delay -> ReponseDelayedinMins\n",
    "2. Retourner un nouveau DataFrame\n",
    "3. Afficher tous les appels où le temps de réponse à un site d'incendie a eu lieu après un retard de plus de 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newFireDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Reponse 3\n",
    "val newFireDF = fireDF.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")\n",
    "newFireDF\n",
    ".select(\"ResponseDelayedinMins\")\n",
    ".filter(col(\"ResponseDelayedinMins\" > 5))\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j'ai appliqué la methode filter() sur la colonne  ResponseDelayedinMins pour recuperer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations des dates  \n",
    "Maintenant nous allons d'abord:  \n",
    "1. Transformer les dates de type String en Spark Timestamp afin que nous puissions effectuer des requêtes basées sur la date plus tard    \n",
    "2. Retourner le Dataframe transformée  \n",
    "3. Mettre en cache le nouveau DataFrame  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fireTSDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n",
       "res12: fireTSDF.type = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fireTSDF = newFireDF\n",
    "  .withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\")).drop(\"CallDate\") \n",
    "  .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\")).drop(\"WatchDate\") \n",
    "  .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"), \"MM/dd/yyyy hh:mm:ss a\")).drop(\"AvailableDtTm\")\n",
    "\n",
    "fireTSDF.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "**Quels sont les types d'appels les plus courants?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+------+\n",
      "|CallType                                    |count |\n",
      "+--------------------------------------------+------+\n",
      "|Administrative                              |3     |\n",
      "|Mutual Aid / Assist Outside Agency          |9     |\n",
      "|Confined Space / Structure Collapse         |13    |\n",
      "|Marine Fire                                 |14    |\n",
      "|Suspicious Package                          |15    |\n",
      "|Oil Spill                                   |21    |\n",
      "|Watercraft in Distress                      |28    |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|28    |\n",
      "|High Angle Rescue                           |32    |\n",
      "|Assist Police                               |35    |\n",
      "|Aircraft Emergency                          |36    |\n",
      "|Train / Rail Incident                       |57    |\n",
      "|Explosion                                   |89    |\n",
      "|Industrial Accidents                        |94    |\n",
      "|HazMat                                      |124   |\n",
      "|Fuel Spill                                  |193   |\n",
      "|Smoke Investigation (Outside)               |391   |\n",
      "|Elevator / Escalator Rescue                 |453   |\n",
      "|Electrical Hazard                           |482   |\n",
      "|Odor (Strange / Unknown)                    |490   |\n",
      "|Water Rescue                                |755   |\n",
      "|Gas Leak (Natural and LP Gases)             |764   |\n",
      "|Vehicle Fire                                |854   |\n",
      "|Outside Fire                                |2094  |\n",
      "|Other                                       |2166  |\n",
      "|Citizen Assist / Service Call               |2524  |\n",
      "|Traffic Collision                           |7013  |\n",
      "|Alarms                                      |19406 |\n",
      "|Structure Fire                              |23319 |\n",
      "|Medical Incident                            |113794|\n",
      "+--------------------------------------------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CDistinctCallT: org.apache.spark.sql.DataFrame = [CallType: string, count: bigint]\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/// 1) On recupere le nombre de type d'appel, pour chaque type d'appel\n",
    "\n",
    "val CDistinctCallT =  fireDF.groupBy(\"CallType\").count()\n",
    "CDistinctCallT.orderBy(\"count\").show(30, false)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5-a\n",
    "**Quels sont boites postaux rencontrés dans les appels les plus courants?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Zipcode|count|\n",
      "+-------+-----+\n",
      "|null   |142  |\n",
      "|94129  |512  |\n",
      "|94158  |882  |\n",
      "|94130  |1100 |\n",
      "|94104  |1341 |\n",
      "|94127  |1881 |\n",
      "|94111  |2974 |\n",
      "|94131  |3236 |\n",
      "|94123  |3719 |\n",
      "|94116  |3933 |\n",
      "|94108  |4084 |\n",
      "|94105  |4236 |\n",
      "|94132  |4321 |\n",
      "|94121  |4555 |\n",
      "|94134  |5009 |\n",
      "|94118  |5157 |\n",
      "|94114  |5175 |\n",
      "|94117  |5804 |\n",
      "|94133  |6246 |\n",
      "|94122  |6355 |\n",
      "|94107  |6941 |\n",
      "|94115  |7812 |\n",
      "|94112  |8421 |\n",
      "|94124  |9236 |\n",
      "|94109  |14686|\n",
      "|94110  |14801|\n",
      "|94103  |20897|\n",
      "|94102  |21840|\n",
      "+-------+-----+\n",
      "\n",
      "+-------+\n",
      "|Zipcode|\n",
      "+-------+\n",
      "|  94109|\n",
      "|  94124|\n",
      "|  94102|\n",
      "|  94109|\n",
      "|  94105|\n",
      "|  94112|\n",
      "|  94102|\n",
      "|  94115|\n",
      "|  94114|\n",
      "|  94110|\n",
      "|  94112|\n",
      "|  94109|\n",
      "|  94121|\n",
      "|  94110|\n",
      "|  94110|\n",
      "|  94110|\n",
      "|  94116|\n",
      "|  94118|\n",
      "|  94118|\n",
      "|  94133|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Zipcode: org.apache.spark.sql.DataFrame = [Zipcode: int, count: bigint]\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 5-a\n",
    "// D'abord, Le nombre Zipcode\n",
    "val Zipcode =  fireDF.groupBy(\"Zipcode\").count()\n",
    "Zipcode.orderBy(\"count\").show(30,false)\n",
    "fireDF.filter($\"CallType\" === \"Medical Incident\" || $\"CallType\" === \"Structure Fire\" || $\"CallType\" ===  \"Alarms\" || $\"CallType\" === \"Traffic Collision\")\n",
    "    .select(\"Zipcode\")\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5-b\n",
    "**Quels sont les quartiers de San Francisco dont les codes postaux sont 94102 et 94103?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             Address|\n",
      "+--------------------+\n",
      "|MARKET ST/MCALLIS...|\n",
      "|600 Block of POLK ST|\n",
      "|    9TH ST/HOWARD ST|\n",
      "|400 Block of VALE...|\n",
      "|  16TH ST/MISSION ST|\n",
      "|   4TH ST/MISSION ST|\n",
      "|400 Block of TURK ST|\n",
      "|   OAK ST/WEBSTER ST|\n",
      "| 0 Block of JONES ST|\n",
      "|400 Block of EDDY ST|\n",
      "|300 Block of CLEM...|\n",
      "| 500 Block of OAK ST|\n",
      "|700 Block of MARK...|\n",
      "|HAIGHT ST/OCTAVIA ST|\n",
      "|100 Block of JULI...|\n",
      "|0 Block of LARKIN ST|\n",
      "|100 Block of TURK ST|\n",
      "|CALL BOX: BUCHANA...|\n",
      "|    5TH ST/MARKET ST|\n",
      "| 100 Block of 7TH ST|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// On fait un filtre avec ces deux \"Zipcode\" specifiquements \n",
    "fireDF .filter($\"Zipcode\" === 94102 || $\"Zipcode\" === 94103).select(\"Address\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "**Determiner le nombre total d'appels, ainsi que la moyenne, le minimum et le maximum du temps de réponse des appels?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+------+\n",
      "|CallType                                    |count |\n",
      "+--------------------------------------------+------+\n",
      "|Elevator / Escalator Rescue                 |453   |\n",
      "|Marine Fire                                 |14    |\n",
      "|Aircraft Emergency                          |36    |\n",
      "|Confined Space / Structure Collapse         |13    |\n",
      "|Administrative                              |3     |\n",
      "|Alarms                                      |19406 |\n",
      "|Odor (Strange / Unknown)                    |490   |\n",
      "|Citizen Assist / Service Call               |2524  |\n",
      "|HazMat                                      |124   |\n",
      "|Watercraft in Distress                      |28    |\n",
      "|Explosion                                   |89    |\n",
      "|Oil Spill                                   |21    |\n",
      "|Vehicle Fire                                |854   |\n",
      "|Suspicious Package                          |15    |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|28    |\n",
      "|Other                                       |2166  |\n",
      "|Outside Fire                                |2094  |\n",
      "|Traffic Collision                           |7013  |\n",
      "|Assist Police                               |35    |\n",
      "|Gas Leak (Natural and LP Gases)             |764   |\n",
      "|Water Rescue                                |755   |\n",
      "|Electrical Hazard                           |482   |\n",
      "|High Angle Rescue                           |32    |\n",
      "|Structure Fire                              |23319 |\n",
      "|Industrial Accidents                        |94    |\n",
      "|Medical Incident                            |113794|\n",
      "|Mutual Aid / Assist Outside Agency          |9     |\n",
      "|Fuel Spill                                  |193   |\n",
      "|Smoke Investigation (Outside)               |391   |\n",
      "|Train / Rail Incident                       |57    |\n",
      "+--------------------------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Reponse 6\n",
    "fireDF.groupBy(\"CallType\").count().show(31,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+\n",
      "|summary|ResponseDelayedinMins|\n",
      "+-------+---------------------+\n",
      "|  count|               175296|\n",
      "|   mean|    3.892364154521585|\n",
      "| stddev|    9.378286226254257|\n",
      "|    min|          0.016666668|\n",
      "|    max|              1844.55|\n",
      "+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newFireDF\n",
    ".select(\"ResponseDelayedinMins\").describe()\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7-a\n",
    "**Combien d'années distinctes trouve t-on dans ce Dataset?**  \n",
    "Dans ce dataset nous avons des données comprises entre 2000-2018. Vous pouvez utilisez la fonction Spark `year()` pour les dates en Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res21: Long = 19\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fireTSDF.select(year(col(\"IncidentDate\")))\n",
    ".distinct()\n",
    ".count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7-b\n",
    "**Quelle semaine de l'année 2018 a eu le plus d'appels d'incendie?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": " cannot resolve '`week_of_year`' given input columns: [ALSUnit, Address, AvailableDtTS, Battalion, Box, CallFinalDisposition, CallNumber, CallType, CallTypeGroup, City, FinalPriority, FirePreventionDistrict, IncidentDate, IncidentNumber, Location, Neighborhood, NumAlarms, OnWatchDate, OriginalPriority, Priority, ResponseDelayedinMins, RowID, StationArea, SupervisorDistrict, UnitID, UnitSequenceInCallDispatch, UnitType, Zipcode];;",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException: cannot resolve '`week_of_year`' given input columns: [ALSUnit, Address, AvailableDtTS, Battalion, Box, CallFinalDisposition, CallNumber, CallType, CallTypeGroup, City, FinalPriority, FirePreventionDistrict, IncidentDate, IncidentNumber, Location, Neighborhood, NumAlarms, OnWatchDate, OriginalPriority, Priority, ResponseDelayedinMins, RowID, StationArea, SupervisorDistrict, UnitID, UnitSequenceInCallDispatch, UnitType, Zipcode];;",
      "'Aggregate ['week_of_year, IncidentDate#2935], ['week_of_year, IncidentDate#2935, count(IncidentDate#2935) AS count#6690L]",
      "+- Project [CallNumber#0, UnitID#1, IncidentNumber#2, CallType#3, CallFinalDisposition#6, Address#8, City#9, Zipcode#10, Battalion#11, StationArea#12, Box#13, OriginalPriority#14, Priority#15, FinalPriority#16, ALSUnit#17, CallTypeGroup#18, NumAlarms#19, UnitType#20, UnitSequenceInCallDispatch#21, FirePreventionDistrict#22, SupervisorDistrict#23, Neighborhood#24, Location#25, RowID#26, ... 4 more fields]",
      "   +- Project [CallNumber#0, UnitID#1, IncidentNumber#2, CallType#3, CallFinalDisposition#6, AvailableDtTm#7, Address#8, City#9, Zipcode#10, Battalion#11, StationArea#12, Box#13, OriginalPriority#14, Priority#15, FinalPriority#16, ALSUnit#17, CallTypeGroup#18, NumAlarms#19, UnitType#20, UnitSequenceInCallDispatch#21, FirePreventionDistrict#22, SupervisorDistrict#23, Neighborhood#24, Location#25, ... 5 more fields]",
      "      +- Project [CallNumber#0, UnitID#1, IncidentNumber#2, CallType#3, CallFinalDisposition#6, AvailableDtTm#7, Address#8, City#9, Zipcode#10, Battalion#11, StationArea#12, Box#13, OriginalPriority#14, Priority#15, FinalPriority#16, ALSUnit#17, CallTypeGroup#18, NumAlarms#19, UnitType#20, UnitSequenceInCallDispatch#21, FirePreventionDistrict#22, SupervisorDistrict#23, Neighborhood#24, Location#25, ... 4 more fields]",
      "         +- Project [CallNumber#0, UnitID#1, IncidentNumber#2, CallType#3, WatchDate#5, CallFinalDisposition#6, AvailableDtTm#7, Address#8, City#9, Zipcode#10, Battalion#11, StationArea#12, Box#13, OriginalPriority#14, Priority#15, FinalPriority#16, ALSUnit#17, CallTypeGroup#18, NumAlarms#19, UnitType#20, UnitSequenceInCallDispatch#21, FirePreventionDistrict#22, SupervisorDistrict#23, Neighborhood#24, ... 5 more fields]",
      "            +- Project [CallNumber#0, UnitID#1, IncidentNumber#2, CallType#3, WatchDate#5, CallFinalDisposition#6, AvailableDtTm#7, Address#8, City#9, Zipcode#10, Battalion#11, StationArea#12, Box#13, OriginalPriority#14, Priority#15, FinalPriority#16, ALSUnit#17, CallTypeGroup#18, NumAlarms#19, UnitType#20, UnitSequenceInCallDispatch#21, FirePreventionDistrict#22, SupervisorDistrict#23, Neighborhood#24, ... 4 more fields]",
      "               +- Project [CallNumber#0, UnitID#1, IncidentNumber#2, CallType#3, CallDate#4, WatchDate#5, CallFinalDisposition#6, AvailableDtTm#7, Address#8, City#9, Zipcode#10, Battalion#11, StationArea#12, Box#13, OriginalPriority#14, Priority#15, FinalPriority#16, ALSUnit#17, CallTypeGroup#18, NumAlarms#19, UnitType#20, UnitSequenceInCallDispatch#21, FirePreventionDistrict#22, SupervisorDistrict#23, ... 5 more fields]",
      "                  +- Project [CallNumber#0, UnitID#1, IncidentNumber#2, CallType#3, CallDate#4, WatchDate#5, CallFinalDisposition#6, AvailableDtTm#7, Address#8, City#9, Zipcode#10, Battalion#11, StationArea#12, Box#13, OriginalPriority#14, Priority#15, FinalPriority#16, ALSUnit#17, CallTypeGroup#18, NumAlarms#19, UnitType#20, UnitSequenceInCallDispatch#21, FirePreventionDistrict#22, SupervisorDistrict#23, ... 4 more fields]",
      "                     +- Relation[CallNumber#0,UnitID#1,IncidentNumber#2,CallType#3,CallDate#4,WatchDate#5,CallFinalDisposition#6,AvailableDtTm#7,Address#8,City#9,Zipcode#10,Battalion#11,StationArea#12,Box#13,OriginalPriority#14,Priority#15,FinalPriority#16,ALSUnit#17,CallTypeGroup#18,NumAlarms#19,UnitType#20,UnitSequenceInCallDispatch#21,FirePreventionDistrict#22,SupervisorDistrict#23,... 4 more fields] csv",
      "",
      "  at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:143)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:140)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$2(TreeNode.scala:333)",
      "  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:333)",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsUp$1(QueryPlan.scala:106)",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:118)",
      "  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:118)",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:129)",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$3(QueryPlan.scala:134)",
      "  at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)",
      "  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)",
      "  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)",
      "  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)",
      "  at scala.collection.TraversableLike.map(TraversableLike.scala:238)",
      "  at scala.collection.TraversableLike.map$(TraversableLike.scala:231)",
      "  at scala.collection.AbstractTraversable.map(Traversable.scala:108)",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:134)",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:139)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:139)",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:106)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:140)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:92)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:177)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:92)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:89)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:130)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:156)",
      "  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:153)",
      "  at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:68)",
      "  at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)",
      "  at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:133)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)",
      "  at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:133)",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:68)",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:66)",
      "  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:58)",
      "  at org.apache.spark.sql.Dataset$.$anonfun$ofRows$1(Dataset.scala:91)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)",
      "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:89)",
      "  at org.apache.spark.sql.RelationalGroupedDataset.toDF(RelationalGroupedDataset.scala:66)",
      "  at org.apache.spark.sql.RelationalGroupedDataset.agg(RelationalGroupedDataset.scala:256)",
      "  ... 42 elided",
      ""
     ]
    }
   ],
   "source": [
    "// Calculer le nombre d'incident par semaine en 2018\n",
    "fireTSDF.groupBy($\"week_of_year\",$\"IncidentDate\")\n",
    ".agg(count($\"IncidentDate\").as(\"count\"))\n",
    ".filter($\"IncidentDate\"\n",
    ".between(\"2018-01-01 00:00:00\",\"2018-12-31 00:00:00\"))\n",
    ".orderBy(desc(\"count\"))\n",
    ".show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "**Quels sont les quartiers de San Francisco qui ont connu le pire temps de réponse en 2018?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "39: error: value show is not a member of Boolean",
     "output_type": "error",
     "traceback": [
      "<console>:39: error: value show is not a member of Boolean",
      "possible cause: maybe a semicolon is missing before `value show'?",
      "       .show(10, false)",
      "        ^",
      ""
     ]
    }
   ],
   "source": [
    "fireTSDF\n",
    "  .select(\"Neighborhood\", \"ResponseDelayedinMins\") where(year($\"IncidentDate\") == 2018)\n",
    ".show(10, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "**Comment stocker les données du Dataframe sous format de fichiers Parquet?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Reponse 9\n",
    "\n",
    "fireDF\n",
    ".write.format(\"parquet\")\n",
    ".saveAsTable(parquetTable)\n",
    "df6.write.parquet(\"MySparkproject.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "**Comment relire les données stockée en format Parquet?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val parquetFileDF = spark.read.parquet(\"MySparkproject.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
